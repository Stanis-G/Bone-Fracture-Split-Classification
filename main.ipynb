{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D, Flatten\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avulsion fracture: 98 / 43\n",
      "Comminuted fracture: 153 / 66\n",
      "Compression-Crush fracture: 105 / 45\n",
      "Fracture Dislocation: 111 / 48\n",
      "Greenstick fracture: 95 / 41\n",
      "Hairline Fracture: 97 / 42\n",
      "Impacted fracture: 112 / 49\n",
      "Intra-articular fracture: 72 / 32\n",
      "Longitudinal fracture: 90 / 39\n",
      "Oblique fracture: 86 / 38\n",
      "Pathological fracture: 90 / 39\n",
      "Spiral Fracture: 93 / 41\n",
      "TOTAL AMOUNT train, test:  1202 / 523\n"
     ]
    }
   ],
   "source": [
    "# Count data\n",
    "\n",
    "total_amount_train, total_amount_test = 0, 0\n",
    "for dir in os.listdir('data/train'):\n",
    "\n",
    "    print(dir, end=': ')\n",
    "    count_train = len(os.listdir(f'data/train/{dir}'))\n",
    "    count_test = len(os.listdir(f'data/test/{dir}'))\n",
    "    print(f'{count_train} /', count_test)\n",
    "    total_amount_train += count_train\n",
    "    total_amount_test += count_test\n",
    "\n",
    "print(f'TOTAL AMOUNT train, test: ', f'{total_amount_train} /', total_amount_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_img(filepath, as_array=False, black_white=False):\n",
    "    \"\"\"Read image, turn it to black and white scale if needed. The result can be returned as img or array\"\"\"\n",
    "    img = Image.open(filepath)\n",
    "    if black_white:\n",
    "        img = img.convert('L')\n",
    "    if as_array:\n",
    "        return np.asarray(img)\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(sample, to_normalize=True, to_pad=False, shape_pad=0):\n",
    "    \"\"\"Read data and return tuple of X and Y data. Extend arrays to some shape with zeros if needed\"\"\"\n",
    "    data, labels = [], []\n",
    "\n",
    "    # Read sample data\n",
    "    for i, dir in enumerate(os.listdir(f'data/{sample}')):\n",
    "\n",
    "        path = f'data/{sample}/{dir}'\n",
    "        # Read one label data\n",
    "        for file in os.listdir(path):\n",
    "\n",
    "            img = read_img(f'{path}/{file}', as_array=True, black_white=True)\n",
    "            if to_pad:\n",
    "                # Extend data to specified shape by putting values to zeros array of shape needed\n",
    "                img_padded = np.zeros(shape_pad)\n",
    "                img_padded[:img.shape[0],:img.shape[1]] = img\n",
    "                img_padded = img_padded.astype('float16')\n",
    "                data.append(img_padded)\n",
    "            else:\n",
    "                data.append(img)\n",
    "            labels.append(i)\n",
    "\n",
    "    data = np.array(data, dtype='object')\n",
    "\n",
    "    if to_normalize:\n",
    "        data = data / 255\n",
    "\n",
    "    return data, np.array(labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\1311117\\anaconda3\\envs\\nn_env\\lib\\site-packages\\PIL\\Image.py:981: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(6714, 4430)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find max image shape in dataset\n",
    "\n",
    "shape_width_max, shape_height_max = 0, 0\n",
    "for dir in os.listdir('data/train'):\n",
    "    for file in os.listdir(f'data/train/{dir}'):\n",
    "        img = read_img(f'data/train/{dir}/{file}', as_array=True, black_white=True)\n",
    "\n",
    "        shape_width, shape_height = img.shape\n",
    "\n",
    "        if shape_width > shape_width_max:\n",
    "            shape_width_max = shape_width\n",
    "\n",
    "        if shape_height > shape_height_max:\n",
    "            shape_height_max = shape_height\n",
    "\n",
    "shape_max = shape_width_max, shape_height_max\n",
    "shape_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 56.7 MiB for an array with shape (6714, 4430) and data type float16",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[98], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Read train data\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m X_train, y_train \u001b[38;5;241m=\u001b[39m \u001b[43mread_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_pad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape_pad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape_max\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(X_train\u001b[38;5;241m.\u001b[39mshape, y_train\u001b[38;5;241m.\u001b[39mshape)\n",
      "Cell \u001b[1;32mIn[97], line 17\u001b[0m, in \u001b[0;36mread_data\u001b[1;34m(sample, to_normalize, to_pad, shape_pad)\u001b[0m\n\u001b[0;32m     15\u001b[0m     img_padded \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(shape_pad)\n\u001b[0;32m     16\u001b[0m     img_padded[:img\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],:img\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]] \u001b[38;5;241m=\u001b[39m img\n\u001b[1;32m---> 17\u001b[0m     img_padded \u001b[38;5;241m=\u001b[39m \u001b[43mimg_padded\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfloat16\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m     data\u001b[38;5;241m.\u001b[39mappend(img_padded)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 56.7 MiB for an array with shape (6714, 4430) and data type float16"
     ]
    }
   ],
   "source": [
    "# Read train data\n",
    "\n",
    "X_train, y_train = read_data('train', to_pad=True, shape_pad=shape_max)\n",
    "\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 227. MiB for an array with shape (6714, 4430) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[75], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m X_test, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mread_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_pad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape_pad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape_max\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(X_test\u001b[38;5;241m.\u001b[39mshape, y_test\u001b[38;5;241m.\u001b[39mshape)\n",
      "Cell \u001b[1;32mIn[70], line 15\u001b[0m, in \u001b[0;36mread_data\u001b[1;34m(sample, to_normalize, to_pad, shape_pad)\u001b[0m\n\u001b[0;32m     12\u001b[0m img \u001b[38;5;241m=\u001b[39m read_img(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, as_array\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, black_white\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m to_pad:\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;66;03m# Extend data to specified shape by putting values to zeros array of shape needed\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     img_padded \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape_pad\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m     img_padded[:img\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],:img\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]] \u001b[38;5;241m=\u001b[39m img\n\u001b[0;32m     17\u001b[0m     data\u001b[38;5;241m.\u001b[39mappend(img_padded)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 227. MiB for an array with shape (6714, 4430) and data type float64"
     ]
    }
   ],
   "source": [
    "X_test, y_test = read_data('test', to_pad=True, shape_pad=shape_max)\n",
    "\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1202, 12) (523, 12)\n"
     ]
    }
   ],
   "source": [
    "y_train_cat = to_categorical(y_train, 12)\n",
    "y_test_cat = to_categorical(y_test, 12)\n",
    "\n",
    "print(y_train_cat.shape, y_test_cat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / 255\n",
    "X_test = X_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22745098039215686"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(\n",
    "        64, # Количество фильтров (каналов)\n",
    "        (5,5), # Размер каждого фильтра\n",
    "        padding='same', # На выходе получится изображение той же размерности, за исключением глубины\n",
    "        activation='relu',\n",
    "    ),\n",
    "    MaxPool2D(\n",
    "        (2,2), # Размер окна\n",
    "        strides=1, # Шаг сканирования\n",
    "        padding='valid', # Не добавлять нулевых значений на границах\n",
    "    ),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(12, activation='softmax'),\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "his = model.fit(\n",
    "    X_train,\n",
    "    y_train_cat,\n",
    "    batch_size=32,\n",
    "    epochs=5,\n",
    "    validation_split=0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nn_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
